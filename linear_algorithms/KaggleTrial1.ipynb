{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bc7624-f3e2-418d-9f78-9468fc98ca6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\saiet\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\saiet\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94332ce",
   "metadata": {
    "id": "d94332ce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9878a99c-d0a1-490a-b3d8-f75e59da5851",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9878a99c-d0a1-490a-b3d8-f75e59da5851",
    "outputId": "f1788725-d9a2-48ae-b822-6f2f936675c8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'age_approx', 'sex', 'anatom_site_general',\n",
       "       'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B',\n",
       "       'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext',\n",
       "       'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio',\n",
       "       'tbp_lv_color_std_mean', 'tbp_lv_deltaA', 'tbp_lv_deltaB',\n",
       "       'tbp_lv_deltaL', 'tbp_lv_deltaLB', 'tbp_lv_deltaLBnorm',\n",
       "       'tbp_lv_eccentricity', 'tbp_lv_location', 'tbp_lv_location_simple',\n",
       "       'tbp_lv_minorAxisMM', 'tbp_lv_nevi_confidence', 'tbp_lv_norm_border',\n",
       "       'tbp_lv_norm_color', 'tbp_lv_perimeterMM',\n",
       "       'tbp_lv_radial_color_std_max', 'tbp_lv_stdL', 'tbp_lv_stdLExt',\n",
       "       'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle', 'tbp_lv_x', 'tbp_lv_y',\n",
       "       'tbp_lv_z', 'mel_mitotic_index', 'mel_thick_mm',\n",
       "       'tbp_lv_dnn_lesion_confidence', '0', '1', '2', '3', '4', '5', '6', '7',\n",
       "       '8', '9', '10', '11', '12', '13', '14', '15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DatasetInitalComplete.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bff362f-a6a8-4044-b6ed-3036f1b02663",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bff362f-a6a8-4044-b6ed-3036f1b02663",
    "outputId": "f86170e9-30e5-4e17-f653-87d8ed747ada",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 399608\n",
      "     target  age_approx  sex  anatom_site_general  clin_size_long_diam_mm  \\\n",
      "0         1        80.0  0.0                  0.0                    9.27   \n",
      "1         1        75.0  1.0                  3.0                    3.88   \n",
      "2         1        80.0  1.0                  0.0                    6.55   \n",
      "3         1        60.0  1.0                  4.0                    5.27   \n",
      "4         1        55.0  1.0                  1.0                    5.29   \n",
      "..      ...         ...  ...                  ...                     ...   \n",
      "387       1        70.0  0.0                  1.0                    5.13   \n",
      "388       1        50.0  0.0                  1.0                    8.16   \n",
      "389       1        60.0  0.0                  1.0                    5.65   \n",
      "390       1        60.0  1.0                  2.0                    8.51   \n",
      "391       1        65.0  0.0                  2.0                   12.08   \n",
      "\n",
      "      tbp_lv_A  tbp_lv_Aext   tbp_lv_B  tbp_lv_Bext   tbp_lv_C  ...         6  \\\n",
      "0    18.093367    13.054772  19.090458    21.211776  26.302386  ...  0.952930   \n",
      "1    26.187010    21.394010  25.553420    24.914770  36.588750  ...  0.991787   \n",
      "2    33.480140    24.249430  26.160100    25.295430  42.488470  ...  0.849163   \n",
      "3    25.872050    20.194650  26.805590    28.459890  37.254570  ...  0.832057   \n",
      "4    30.966662    22.008635  24.066940    26.734379  39.219278  ...  0.877775   \n",
      "..         ...          ...        ...          ...        ...  ...       ...   \n",
      "387  24.068933    18.656887  28.149071    29.237257  37.036249  ...  0.896274   \n",
      "388  17.351658    11.348823  23.910937    24.652597  29.543408  ...  0.925763   \n",
      "389  21.990980    14.083370  34.254300    33.717530  40.705780  ...  0.886412   \n",
      "390  19.003400    11.828330  21.741510    23.470120  28.875990  ...  0.849916   \n",
      "391  23.465230    18.400280  17.359240    20.595300  29.188360  ...  0.964035   \n",
      "\n",
      "            7         8          9        10        11        12        13  \\\n",
      "0    4.176777  0.240838  37.515355  0.032714  0.902516  5.879538  0.187503   \n",
      "1    3.597081  0.315452  29.518401  0.084921  0.986034  4.764154  0.263450   \n",
      "2    5.199315  0.192565  56.186421  0.030268  0.711213  7.140923  0.146844   \n",
      "3    4.776675  0.194337  38.999721  0.037905  0.695784  6.448128  0.147726   \n",
      "4    4.814873  0.197552  42.312589  0.034222  0.777349  6.516821  0.151383   \n",
      "..        ...       ...        ...       ...       ...       ...       ...   \n",
      "387  6.484188  0.149976  70.916421  0.022737  0.773444  9.606231  0.105610   \n",
      "388  3.580939  0.261009  26.182868  0.045197  0.863114  4.650359  0.216056   \n",
      "389  3.484036  0.251929  21.138046  0.042917  0.791210  4.678256  0.198612   \n",
      "390  6.582817  0.149545  75.800685  0.028989  0.727156  8.864513  0.116278   \n",
      "391  3.585939  0.258121  23.653350  0.040172  0.931163  4.904692  0.204355   \n",
      "\n",
      "             14        15  \n",
      "0     78.068154  0.141073  \n",
      "1     50.192256  0.181296  \n",
      "2    107.892820  0.150849  \n",
      "3     71.002179  0.180971  \n",
      "4     77.515538  0.165631  \n",
      "..          ...       ...  \n",
      "387  155.547513  0.134730  \n",
      "388   48.550462  0.177636  \n",
      "389   39.082051  0.182451  \n",
      "390  138.390667  0.156015  \n",
      "391   45.486077  0.158717  \n",
      "\n",
      "[392 rows x 58 columns]\n",
      "        target  age_approx  sex  anatom_site_general  clin_size_long_diam_mm  \\\n",
      "392          0        60.0  1.0                  2.0                    3.04   \n",
      "393          0        60.0  1.0                  3.0                    1.10   \n",
      "394          0        60.0  1.0                  1.0                    3.40   \n",
      "395          0        65.0  1.0                  0.0                    3.22   \n",
      "396          0        55.0  1.0                  0.0                    2.73   \n",
      "...        ...         ...  ...                  ...                     ...   \n",
      "399995       0        60.0  0.0                  1.0                    3.10   \n",
      "399996       0        65.0  1.0                  4.0                    2.66   \n",
      "399997       0        65.0  0.0                  4.0                    4.66   \n",
      "399998       0        50.0  1.0                  4.0                    2.62   \n",
      "399999       0        60.0  0.0                  1.0                    4.02   \n",
      "\n",
      "         tbp_lv_A  tbp_lv_Aext   tbp_lv_B  tbp_lv_Bext   tbp_lv_C  ...  \\\n",
      "392     20.244422    16.261975  26.922447    23.954773  33.684638  ...   \n",
      "393     31.712570    25.364740  26.331000    24.549290  41.219030  ...   \n",
      "394     22.575830    17.128170  37.970460    33.485410  44.174920  ...   \n",
      "395     14.242329    12.164757  21.448144    21.121356  25.746200  ...   \n",
      "396     24.725520    20.057470  26.464900    25.710460  36.217980  ...   \n",
      "...           ...          ...        ...          ...        ...  ...   \n",
      "399995  20.396390     8.700477  19.498260    22.526430  28.216930  ...   \n",
      "399996  18.325057    14.385684  27.391522    25.084622  32.956080  ...   \n",
      "399997  21.155608    17.250798  27.887630    23.743460  35.003995  ...   \n",
      "399998  20.209510    16.428130  34.063210    31.104090  39.607160  ...   \n",
      "399999  24.271200    20.472300  28.256910    28.316620  37.249750  ...   \n",
      "\n",
      "               6         7         8           9        10        11  \\\n",
      "392     0.689648  5.411980  0.171330   48.524721  0.036808  0.450489   \n",
      "393     0.619682  8.554492  0.120635  127.504239  0.026292  0.324255   \n",
      "394     0.844053  4.707030  0.194414   36.768553  0.032908  0.705629   \n",
      "395     0.922334  3.382386  0.255483   18.863655  0.037450  0.857483   \n",
      "396     0.794775  5.151701  0.176295   42.715964  0.031637  0.593174   \n",
      "...          ...       ...       ...         ...       ...       ...   \n",
      "399995  0.964553  1.773858  0.436643    6.484213  0.071432  0.934127   \n",
      "399996  0.857096  4.356041  0.208423   32.171421  0.034872  0.764686   \n",
      "399997  0.806044  4.986041  0.183824   41.111117  0.036125  0.640146   \n",
      "399998  0.823461  4.244188  0.211837   30.236066  0.039569  0.682310   \n",
      "399999  0.864524  5.976675  0.158419   59.231294  0.025248  0.744886   \n",
      "\n",
      "               12        13          14        15  \n",
      "392      7.248205  0.132005   85.868205  0.184861  \n",
      "393     11.451564  0.091993  226.672487  0.155876  \n",
      "394      6.486821  0.144382   69.305692  0.164095  \n",
      "395      4.603385  0.195774   34.346821  0.159876  \n",
      "396      7.285615  0.129315   84.614128  0.167055  \n",
      "...           ...       ...         ...       ...  \n",
      "399995   2.356538  0.356272   12.128538  0.211512  \n",
      "399996   5.665769  0.164533   52.855308  0.164087  \n",
      "399997   6.841718  0.138001   76.429667  0.177144  \n",
      "399998   5.675103  0.164069   54.106333  0.182123  \n",
      "399999   8.238333  0.116490  110.887256  0.142058  \n",
      "\n",
      "[399608 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "df.sort_values(by='target', ascending = False)\n",
    "positives = df[df['target']==1]\n",
    "negatives = df[df['target']==0]\n",
    "print(len(positives),len(negatives))\n",
    "print(positives)\n",
    "print(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24bb424c-d08c-473a-bbef-c6c93dd2bd8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24bb424c-d08c-473a-bbef-c6c93dd2bd8f",
    "outputId": "1589c4f0-481f-4a5f-8ed0-9658d103a24f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(892, 55) (892,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([positives,negatives[0:500]])\n",
    "labels = data['target']\n",
    "data = data.drop(columns=['target','age_approx','mel_thick_mm'])\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "print(data.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243197da-c87c-42d0-b7b7-25379bc50040",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "243197da-c87c-42d0-b7b7-25379bc50040",
    "outputId": "ed069f34-525f-4d23-9e01-afe3ad15a358",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_approx       0.69700\n",
      "mel_thick_mm    99.98425\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "nan_percentage = df.isnull().mean() * 100\n",
    "\n",
    "# Display only columns with NaN values and their percentages\n",
    "columns_with_nan_percentage = nan_percentage[nan_percentage > 0]\n",
    "print(columns_with_nan_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0d32f4-93a3-480d-8ed1-ac318cbf8d7b",
   "metadata": {
    "id": "0c0d32f4-93a3-480d-8ed1-ac318cbf8d7b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data), np.array(labels), test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Add an extra dimension for the output\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).unsqueeze(1)\n",
    "\n",
    "# Create PyTorch DataLoader for efficient batch processing\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d1bdaf-ba29-4db1-97ce-097032892c40",
   "metadata": {
    "id": "28d1bdaf-ba29-4db1-97ce-097032892c40",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self,units):\n",
    "        super(ANN,self).__init__()\n",
    "        self.l1 = nn.Linear(units,units)\n",
    "        #self.l2 = nn.Linear(3*units,2*units)\n",
    "        #self.l3 = nn.Linear(2*units,units)\n",
    "        self.l4 = nn.Linear(units,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = self.lrelu(x)\n",
    "        #x = self.lrelu(self.l2(x))\n",
    "        #x = self.lrelu(self.l3(x))\n",
    "        x = self.sigmoid(self.l4(x))\n",
    "        return torch.round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4986684a-59ae-431e-9ce5-319dcc5bbb94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4986684a-59ae-431e-9ce5-319dcc5bbb94",
    "outputId": "e7bcc6f4-e1e2-418c-da74-4554726fb7d1",
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x55 and 39x39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mANN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1(x)\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(x)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#x = self.lrelu(self.l2(x))\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#x = self.lrelu(self.l3(x))\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x55 and 39x39)"
     ]
    }
   ],
   "source": [
    "loss_fn=nn.BCELoss()\n",
    "model = ANN(units=39)\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.008)\n",
    "device=torch.device( \"cpu\")\n",
    "model.to(device)\n",
    "eval_losses=[]\n",
    "eval_accu=[]\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    correct=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        for data in (test_loader):\n",
    "            inputs,labels=data[0].to(device),data[1].to(device)\n",
    "            outputs=model(inputs)\n",
    "            loss= loss_fn(outputs,labels)\n",
    "            running_loss+=loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    test_loss=running_loss/len(test_loader)\n",
    "    accu=correct/total\n",
    "    eval_losses.append(test_loss)\n",
    "    eval_accu.append(accu)\n",
    "    print('Test Loss: %.3f | Accuracy: %.3f'%(test_loss,accu))\n",
    "\n",
    "# Train the model and capture gradient information\n",
    "epochs = 10\n",
    "gradients = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "\n",
    "        # Capture the gradient of the first layer's weights\n",
    "        gradients.append(model.l1.weight.grad.clone().detach().numpy())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Gradient values after each epoch\n",
    "gradients[-1]  # Showing the last gradient value for the first layer after the final epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb97ecc-0441-454e-834a-c46697e490c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcb97ecc-0441-454e-834a-c46697e490c5",
    "outputId": "658ecb66-5754-49a2-af12-a7118bc858c8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.l1.weight.grad.clone().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5cf25-00e9-4a2f-a153-18847a473570",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58a5cf25-00e9-4a2f-a153-18847a473570",
    "outputId": "717316cb-efa5-40f5-ee68-ee04240918e8"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "    accu=correct/total\n",
    "    # Print the average loss for each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}, Accuracy : {accu:.4f}\")\n",
    "\n",
    "# Gradient values after each epoch\n",
    "# Showing the last gradient value for the first layer after the final epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H8RF-wA4VYff",
   "metadata": {
    "id": "H8RF-wA4VYff"
   },
   "outputs": [],
   "source": [
    "regularizer\n",
    "dropout\n",
    "batchnorm\n",
    "model complexity\n",
    "decrease sample size"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
